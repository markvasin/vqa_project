model_config:
  vqa_transformer:
    direct_features_input: true
    finetune_lr_multiplier: 1
    # Dimension of the embedding finally returned by the modal encoder
    image_hidden_size: 2048
    # Dimension of the embedding finally returned by the text encoder
    text_hidden_size: 256
    num_segment_type: 2
    hidden_size: 256
    num_hidden_layers: 6
    num_attention_heads: 4
    intermediate_size: 1024
    hidden_act: "gelu"
    # Used when classification head is activated
    num_labels: 2
    losses:
    - type: cross_entropy

    hidden_dropout_prob: 0.1
    layer_norm_eps: 1e-12

    text_embedding:
      embedding_dim: 300
    lstm:
      input_size: 300
      hidden_size: 128
      bidirectional: true
      batch_first: true
